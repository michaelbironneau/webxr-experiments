<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, user-scalable=no"
    />
    <meta name="mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png" />
    <link rel="icon" type="image/png" sizes="96x96" href="favicon-96x96.png" />
    <link rel="stylesheet" href="css/common.css" />
    <script
      src="https://cdnjs.cloudflare.com/ajax/libs/tone/14.8.32/Tone.js"
      integrity="sha512-USKCQh+O8BX/a2K06xPNTwduhmQvN/m9FhkR7PRysCRlPoqIItl7Qz3xVTZC/oIHe6g5XvnLHDUgGpRMZZTmFQ=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>
    <title>"Echolocation" example</title>
  </head>
  <body>
    <div id="overlay">
      <header>
        <details open>
          <summary>Spatial audio as echolocation</summary>
          <p>
            This sample illustrates how we can use the depth information from
            the device, combined with a panner, to help a visually impaired user
            navigate a complex space.
            <a class="back" href="./index.html">Back</a>
          </p>
          <div id="session-info"></div>
          <div id="pose"></div>
          <div id="depth"></div>
          <div id="warning-zone"></div>
          <button id="xr-button" class="barebones-button" disabled>
            XR not found
          </button>
        </details>
      </header>
    </div>
    <main style="text-align: center">
      <p>Click 'Enter AR' to see content</p>
    </main>
    <script type="module">
      // XR globals.
      let xrButton = document.getElementById("xr-button");
      let xrSession = null;
      let xrRefSpace = null;

      // WebGL scene globals.
      let gl = null;

      function checkSupportedState() {
        navigator.xr.isSessionSupported("immersive-ar").then((supported) => {
          if (supported) {
            xrButton.innerHTML = "Enter AR";
          } else {
            xrButton.innerHTML = "AR not found";
          }

          xrButton.disabled = !supported;
        });
      }

      function initXR() {
        if (!window.isSecureContext) {
          let message = "WebXR unavailable due to insecure context";
          document.getElementById("warning-zone").innerText = message;
        }
        xrButton.addEventListener("click", function () {
          console.log("Started Audio Context");
          Tone.start();
        });
        if (navigator.xr) {
          xrButton.addEventListener("click", onButtonClicked);
          navigator.xr.addEventListener("devicechange", checkSupportedState);
          checkSupportedState();
        }
      }

      function onButtonClicked() {
        if (!xrSession) {
          // Ask for an optional DOM Overlay, see https://immersive-web.github.io/dom-overlays/
          navigator.xr
            .requestSession("immersive-ar", {
              optionalFeatures: ["dom-overlay"],
              requiredFeatures: ["depth-sensing"],
              depthSensing: {
                usagePreference: ["cpu-optimized", "gpu-optimized"],
                dataFormatPreference: ["float32", "luminance-alpha"],
              },
              domOverlay: { root: document.getElementById("overlay") },
            })
            .then(onSessionStarted, onRequestSessionError);
        } else {
          xrSession.end();
        }
      }

      function onSessionStarted(session) {
        xrSession = session;
        xrButton.innerHTML = "Exit AR";
        audioObj.near.start();
        // Show which type of DOM Overlay got enabled (if any)
        if (session.domOverlayState) {
          document.getElementById("session-info").innerHTML =
            "DOM Overlay type: " + session.domOverlayState.type;
        }

        session.addEventListener("end", onSessionEnded);
        let canvas = document.createElement("canvas");
        gl = canvas.getContext("webgl", {
          xrCompatible: true,
        });
        session.updateRenderState({ baseLayer: new XRWebGLLayer(session, gl) });
        session.requestReferenceSpace("local").then((refSpace) => {
          xrRefSpace = refSpace;
          session.requestAnimationFrame(onXRFrame);
        });
      }

      function onRequestSessionError(ex) {
        alert("Failed to start immersive AR session.");
        console.error(ex.message);
      }

      function onEndSession(session) {
        session.end();
      }

      function onSessionEnded(event) {
        xrSession = null;
        xrButton.innerHTML = "Enter AR";
        audioObj.near.stop();
        document.getElementById("session-info").innerHTML = "";
        gl = null;
      }

      function getDepthDetails(depthInfo) {
        let runningTotal = 0;
        const WIDTH = 15;
        const HEIGHT = 15;
        let minimum = 50;
        let maximum = -1;
        let minPos = { x: 0, y: 0 };

        for (var i = 0; i < WIDTH; i++) {
          for (var j = 0; j < HEIGHT; j++) {
            const x = depthInfo.getDepthInMeters(i / WIDTH, j / HEIGHT);
            if (x < minimum) {
              minimum = x;
              minPos.x = i / WIDTH;
              minPos.y = j / HEIGHT;
            }
            if (x > maximum) {
              maximum = x;
            }
          }
        }

        return { min: minimum, max: maximum, minPos: minPos };
      }

      function showDepthOverlay(frame, pose) {
        let depthInfo = undefined;
        try {
          depthInfo = frame.getDepthInformation(pose.views[0]);
          if (!depthInfo) {
            document.getElementById("depth").innerText = "No depth info!";
            return;
          }
          document.getElementById("depth").innerText = "";
          const info = getDepthDetails(depthInfo);
          audioObj.panner.set({
            positionX: -1 + info.minPos.x * 2,
            positionY: -1 + info.minPos.y * 2,
            positionZ: info.min,
          });
          audioObj.near.set({ volume: -10 - 5 * info.min });
          if (info.min < 0.5) {
            audioObj.collision.start();
            audioObj.collision.set({ volume: -9 - 5 * info.min });
          } else {
            audioObj.collision.stop();
          }
          document.getElementById("depth").innerText = `Pan: ${
            -1 + info.minPos.x * 2
          }, Vol: ${-10 - 5 * info.min}`;
        } catch (ex) {
          document.getElementById("depth").innerText = ex;
          return;
        }
      }

      function setupAudio() {
        const panner = new Tone.Panner3D({
          panningModel: "HRTF",
        }).toDestination();

        const filter1 = new Tone.AutoFilter({
          frequency: 1,
          depth: 1,
        })
          .connect(panner)
          .start();

        const oscNear = new Tone.Oscillator({
          volume: -12,
          type: "square6",
          frequency: "E4",
        }).connect(filter1);

        const oscCollision = new Tone.Oscillator({
          volume: -12,
          type: "square6",
          frequency: "C5",
        }).connect(filter1);

        return { panner: panner, near: oscNear, collision: oscCollision };
      }

      function onXRFrame(t, frame) {
        let session = frame.session;
        session.requestAnimationFrame(onXRFrame);
        let pose = frame.getViewerPose(xrRefSpace);
        if (pose) {
          const p = pose.transform.position;
          document.getElementById("pose").innerText =
            "Position: " +
            p.x.toFixed(3) +
            ", " +
            p.y.toFixed(3) +
            ", " +
            p.z.toFixed(3);
          showDepthOverlay(frame, pose);
        } else {
          document.getElementById("pose").innerText = "Position: (null pose)";
        }
      }
      const audioObj = setupAudio();
      initXR();
    </script>
  </body>
</html>
